NAME: Jeffrey Chan
EMAIL: jeffschan97@gmail.com
ID: 004-611-638

Answer to Questions:

2.1.1 - Causing Conflicts
The reason why it takes so many iterations before errors are seen is because a
larger number of iterations increases the chances of race conditions within the
critical sections of the counter code. The reason why having a significantly
smaller number of iterations seldom fails is because the chances of race
conditions within the critical sections is significantly lower because we're
not running the critical section as much.

2.1.2 - Cost of Yielding
The reason why the --yield runs are so much slower is because the yield option
forces the threads to yield the CPU once before they can continue to increment
or decrement the counter. Yielding the CPU means that a context switch needs to
occur so that another thread can run on the CPU. All the additional time is
going into context switching because contexting switching is and expensive
opperation. No, it's not possible to get valid per-operation timings when using
the --yield option because the large amount of time spent on performing a
context switch is included in the running time. Thus the total time of the
program doesn't accurately reflect time the program took to run its operations.

2.1.3 - Measurement Errors
When the number of iterations is small, the run time of the program is
dominated by the thread creation, and thus the average cost per operation is
perceived as higher because we weigh in thread creation time. As the number
of iterations increases, thread creation time becomes less significant and most
of the program's run time is spent actually doing the operations, and thus
the average cost per operation is perceived as lower. Thus, we see that the
cost per operation is inversely proportional to the number of iterations.
Theoretically, we can obtain the "correct" cost by tending the number of
iterations towards infinity, or just a really large number.

2.1.4 - Costs of Serialization
For a low number of threads, all the options perform similarly because the
program makes use of multiple CPU's. The number of threads is small enough such
that each thread can have its own CPU and thus run without having to wait to
obtain the lock to run critical code. Thus all the options with a low number
of threads act similarly in that their threads don't have to waste time waiting
for the lock and can execute critical code sequentially on different CPU's.
As the number of threads rises, there will not be enough CPU's for each thread,
so some threads will have to waste their time slice waiting for the lock,
which dramatically slows down the run time.

Included Files:

Resources:
